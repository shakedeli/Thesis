\chapter{Conclusion and open questions}
\label{chap:conclusion}



We presented Quancurrent, a concurrent scalable Quantiles sketch. We have evaluated it and shown it to be linearly scalable for both updates and queries while providing accurate estimates, i.e., retaining a small error bound with reasonable query freshness. Moreover, it achieves higher performance than state-of-the-art concurrent quantiles solutions with better query freshness.

Quancurrent's scalability arises from allowing multiple threads to engage concurrently in merge-sorts, which are a sequential bottleneck in previous solutions. We dramatically reduce the synchronization overhead by accommodating occasional data races that cause samples to be duplicated or dropped, a phenomenon we refer to as holes. This approach leverages the observation that sketches are approximate to begin with, and so the impact of such holes is marginal.

Future work may leverage this observation to achieve high scalability in other sketches or approximation algorithms.

Another direction for future work is using a Quantiles sketch to implement a search index. Index structures are used when fast data access is needed. Such data structures are critical in practical settings, where the large amounts of underlying data is paired with high search volumes and with a high level of concurrency on the hardware side via tens or even hundreds of parallel threads. 

% Range index structures, like B-Trees, return the location of a value within a key sorted set. It is common for the index always to be stored in the main memory, with the data itself sitting on disk.
Indexes have been more memory, cache and/or CPU efficient in the past decades. It is common for the index structure always to be stored in the main memory, with the data itself sitting on disk. The B-Tree is a commonly used index structure, which return the location of a value within a key sorted set. 

Kraska et al.~\cite{case_learned_index} suggested that traditional index structures can be enhanced, or even replaced, with learned models, including deep-learning models, termed \emph{learned indexes}. Continuous function, describing the data distribution, can be used to build more efficient data structures or algorithms. As noted by Kraska et al.~\cite{case_learned_index}, indexes are models. For example, a B-Tree can be considered as a model which takes a key as an input and returns the position of a record within a sorted array. Instead of a B-Tree, they suggested a recursive model index. That is, build a hierarchy of models, where at each stage the model takes the key as an input and based on it picks another model, until the final stage predicts the position.

Quantile sketches can summarize large amounts of data in sub-linear space complexity. Therefore, We can use Quantiles sketches to reduce the memory overhead of an index. Also, Quantiles sketch can be used to approximate the data distribution and optimizing different types of index structures.

